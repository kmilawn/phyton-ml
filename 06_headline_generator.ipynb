{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmilawn/phyton-ml/blob/main/06_headline_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3nADOBvV1mk"
      },
      "source": [
        "# Sequence Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V41cwYwiV1mm",
        "outputId": "4b90b2ef-ec0d-40c7-ae49-df91a5aaa30f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9335"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "nyt_dir = 'data/nyt_dataset/articles/'\n",
        "\n",
        "all_headlines = []\n",
        "for filename in os.listdir(nyt_dir):\n",
        "    if 'Articles' in filename:\n",
        "        # Read in all the data from the CSV file\n",
        "        headlines_df = pd.read_csv(nyt_dir + filename)\n",
        "        # Add all of the headlines to our list\n",
        "        all_headlines.extend(list(headlines_df.headline.values))\n",
        "len(all_headlines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXK_ZA_jV1mn",
        "outputId": "ba13b69e-c41d-4ee8-efb5-bdf3821ff40f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['My Beijing: The Sacred City',\n",
              " '6 Million Riders a Day, 1930s Technology',\n",
              " 'Seeking a Cross-Border Conference',\n",
              " 'Questions for: ‘Despite the “Yuck Factor,” Leeches Are Big in Russian Medicine’',\n",
              " 'Who Is a ‘Criminal’?',\n",
              " 'An Antidote to Europe’s Populism',\n",
              " 'The Cost of a Speech',\n",
              " 'Degradation of the Language',\n",
              " 'On the Power of Being Awful',\n",
              " 'Trump Garbles Pitch on a Revised Health Bill',\n",
              " 'What’s Going On in This Picture? | May 1, 2017',\n",
              " 'Unknown',\n",
              " 'When Patients Hit a Medical Wall',\n",
              " 'Unknown',\n",
              " 'For Pregnant Women, Getting Serious About Whooping Cough',\n",
              " 'Unknown',\n",
              " 'New York City Transit Reporter in Wonderland: Riding the London Tube',\n",
              " 'How to Cut an Avocado Without Cutting Yourself',\n",
              " 'In Fictional Suicide, Health Experts Say They See a Real Cause for Alarm',\n",
              " 'Claims of Liberal Media Bias Hit ESPN, Too']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_headlines[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Zv1C5YfV1mo",
        "outputId": "9e7c2ca4-bff8-47b5-cdf9-3be108cec861"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8603"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remove all headlines with the value of \"Unknown\"\n",
        "all_headlines = [h for h in all_headlines if h != \"Unknown\"]\n",
        "len(all_headlines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oU0kKXUKV1mo",
        "outputId": "357d6da3-9b69-4967-9c15-7fbddb92cddf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['My Beijing: The Sacred City',\n",
              " '6 Million Riders a Day, 1930s Technology',\n",
              " 'Seeking a Cross-Border Conference',\n",
              " 'Questions for: ‘Despite the “Yuck Factor,” Leeches Are Big in Russian Medicine’',\n",
              " 'Who Is a ‘Criminal’?',\n",
              " 'An Antidote to Europe’s Populism',\n",
              " 'The Cost of a Speech',\n",
              " 'Degradation of the Language',\n",
              " 'On the Power of Being Awful',\n",
              " 'Trump Garbles Pitch on a Revised Health Bill',\n",
              " 'What’s Going On in This Picture? | May 1, 2017',\n",
              " 'When Patients Hit a Medical Wall',\n",
              " 'For Pregnant Women, Getting Serious About Whooping Cough',\n",
              " 'New York City Transit Reporter in Wonderland: Riding the London Tube',\n",
              " 'How to Cut an Avocado Without Cutting Yourself',\n",
              " 'In Fictional Suicide, Health Experts Say They See a Real Cause for Alarm',\n",
              " 'Claims of Liberal Media Bias Hit ESPN, Too',\n",
              " 'Is the dream in Australia crumbling?',\n",
              " 'Police in Texas Change Account in Officer’s Fatal Shooting of 15-Year-Old',\n",
              " 'Most Adults Favor Sex Ed. Most Students Don’t Get It.']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_headlines[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nOOJ1XbV1mo",
        "outputId": "fb0336f5-b551-4d62-a975-a5ef5c56e4c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total words:  11753\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Tokenize the words in our headlines\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(all_headlines)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "print('Total words: ', total_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNYQDW-dV1mp",
        "outputId": "95596137-f11a-4cea-cf29-d36da92dec4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'a': 2, 'plan': 82, 'man': 139, 'panama': 2732, 'canal': 7047}\n"
          ]
        }
      ],
      "source": [
        "# Print a subset of the word_index dictionary created by Tokenizer\n",
        "subset_dict = {key: value for key, value in tokenizer.word_index.items() \\\n",
        "               if key in ['a','man','a','plan','a','canal','panama']}\n",
        "print(subset_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_XtilpjV1mp",
        "outputId": "7f57010e-4ce5-470f-e726-c425ff05b9a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[2], [139], [2], [82], [2], [7047], [2732]]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.texts_to_sequences(['a','man','a','plan','a','canal','panama'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wptCfZ90V1mp",
        "outputId": "b86585cd-f1f9-42c0-ac2f-aa497df85b44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['my beijing', 'my beijing the', 'my beijing the sacred', 'my beijing the sacred city', '6 million']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[[52, 1616],\n",
              " [52, 1616, 1],\n",
              " [52, 1616, 1, 1992],\n",
              " [52, 1616, 1, 1992, 125],\n",
              " [126, 346]]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert data to sequence of tokens\n",
        "input_sequences = []\n",
        "for line in all_headlines:\n",
        "    # Convert our headline into a sequence of tokens\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\n",
        "    # Create a series of sequences for each headline\n",
        "    for i in range(1, len(token_list)):\n",
        "        partial_sequence = token_list[:i+1]\n",
        "        input_sequences.append(partial_sequence)\n",
        "\n",
        "print(tokenizer.sequences_to_texts(input_sequences[:5]))\n",
        "input_sequences[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2C4AcSGV1mp"
      },
      "source": [
        "## Padding Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e34Bm5tOV1mp",
        "outputId": "b4e91c05-29e0-4be4-836f-1e00e74befdd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,   52, 1616], dtype=int32)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Determine max sequence length\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "\n",
        "# Pad all sequences with zeros at the beginning to make them all max length\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "input_sequences[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5M7h2M4V1mq"
      },
      "source": [
        "## Creating Predictors and Target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RxkdQ6hV1mq"
      },
      "source": [
        "<table>\n",
        "<tr><td>PREDICTORS </td> <td>           TARGET </td></tr>\n",
        "<tr><td>nvidia                   </td> <td>  releases </td></tr>\n",
        "<tr><td>nvidia releases               </td> <td>  ampere </td></tr>\n",
        "<tr><td>nvidia releases ampere      </td> <td>  graphics</td></tr>\n",
        "<tr><td>nvidia releases ampere graphics </td> <td>  cards</td></tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPcVtIqwV1mq",
        "outputId": "2e90e1bf-4dc0-41b2-c342-c9e7a5fa98c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1616,    1, 1992,  125,  346], dtype=int32)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Predictors are every word except the last\n",
        "predictors = input_sequences[:,:-1]\n",
        "# Labels are the last word\n",
        "labels = input_sequences[:,-1]\n",
        "labels[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9i6XqXCSV1mq"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import utils\n",
        "\n",
        "labels = utils.to_categorical(labels, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twg5N3WiV1mq"
      },
      "source": [
        "## Creating the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRNK9HK4V1mu"
      },
      "source": [
        "### [Embedding Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyerwM27V1mv"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Input is max sequence length - 1, as we've removed the last word for the label\n",
        "input_len = max_sequence_len - 1\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Add input embedding layer\n",
        "model.add(Embedding(total_words, 10, input_length=input_len))\n",
        "\n",
        "# Add LSTM layer with 100 units\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "# Add output layer\n",
        "model.add(Dense(total_words, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RA_VYnNV1mv",
        "outputId": "7122e9ea-6685-47b2-f4fe-8ca77e248306"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 27, 10)            117530    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 100)               44400     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 11753)             1187053   \n",
            "=================================================================\n",
            "Total params: 1,348,983\n",
            "Trainable params: 1,348,983\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wlDFqPXV1mv"
      },
      "source": [
        "## Compiling the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKfUPmTzV1mv"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-UA6aJLV1mv"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "QMvEHytXV1mw",
        "outputId": "962d73f0-252a-47b3-d944-5ee3918739f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1666/1666 [==============================] - 7s 5ms/step - loss: 7.8844\n",
            "Epoch 2/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 7.4662\n",
            "Epoch 3/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 7.2597\n",
            "Epoch 4/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 7.0413\n",
            "Epoch 5/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 6.8059\n",
            "Epoch 6/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 6.5669\n",
            "Epoch 7/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 6.3289\n",
            "Epoch 8/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 6.0923\n",
            "Epoch 9/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 5.8652\n",
            "Epoch 10/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 5.6438\n",
            "Epoch 11/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 5.4327\n",
            "Epoch 12/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 5.2319\n",
            "Epoch 13/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 5.0396\n",
            "Epoch 14/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 4.8587\n",
            "Epoch 15/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 4.6898\n",
            "Epoch 16/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 4.5241\n",
            "Epoch 17/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 4.3712\n",
            "Epoch 18/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 4.2282\n",
            "Epoch 19/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 4.0919\n",
            "Epoch 20/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.9650\n",
            "Epoch 21/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.8485\n",
            "Epoch 22/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.7336\n",
            "Epoch 23/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.6284\n",
            "Epoch 24/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.5313\n",
            "Epoch 25/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.4410\n",
            "Epoch 26/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.3510\n",
            "Epoch 27/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.2669\n",
            "Epoch 28/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.1915\n",
            "Epoch 29/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.1173\n",
            "Epoch 30/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.0534\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdd03cbf898>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(predictors, labels, epochs=30, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKapUZGGV1mw"
      },
      "source": [
        "## Discussion of Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQ-8p45NV1mx"
      },
      "outputs": [],
      "source": [
        "def predict_next_token(seed_text):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    prediction = model.predict_classes(token_list, verbose=0)\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rp49iaikV1mx",
        "outputId": "d13ea40c-3f12-4c22-9c5a-8c6948823a2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-16-bd91571ab9e2>:4: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([7010])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction = predict_next_token(\"today in new york\")\n",
        "prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48yd5tPCV1my"
      },
      "source": [
        "Let's use our tokenizer to decode the predicted word:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EH00uQ4cV1my",
        "outputId": "4492fd78-db9b-4c2f-f071-ad6e8ebee3e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['subway’s']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.sequences_to_texts([prediction])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2cj7OihV1my"
      },
      "source": [
        "## Generate New Headlines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N71cKmXVV1my"
      },
      "outputs": [],
      "source": [
        "def generate_headline(seed_text, next_words=1):\n",
        "    for _ in range(next_words):\n",
        "        # Predict next token\n",
        "        prediction = predict_next_token(seed_text)\n",
        "        # Convert token to word\n",
        "        next_word = tokenizer.sequences_to_texts([prediction])[0]\n",
        "        # Add next word to the headline. This headline will be used in the next pass of the loop.\n",
        "        seed_text += \" \" + next_word\n",
        "    # Return headline as title-case\n",
        "    return seed_text.title()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9qZWNhNV1my",
        "outputId": "d381cd3f-aa37-44c9-d684-fa3783c57c53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Washington Dc Is A New Ground To Win\n",
            "Today In New York Subway’S Service And Straphangers Fuming\n",
            "The School District Has The President States Should Do\n",
            "Crime Has Become A Blow On A Second\n"
          ]
        }
      ],
      "source": [
        "seed_texts = [\n",
        "    'washington dc is',\n",
        "    'today in new york',\n",
        "    'the school district has',\n",
        "    'crime has become']\n",
        "for seed in seed_texts:\n",
        "    print(generate_headline(seed, next_words=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcNJjZ_XV1mz",
        "outputId": "f1c4f35a-d479-46aa-9ea8-41a6c9134411"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import IPython\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}